{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google's PageRank algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- [Wikipedia article on PageRank](https://en.wikipedia.org/wiki/PageRank)\n",
    "- Original PageRank paper: Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry (1999) [The PageRank Citation Ranking: Bringing Order to the Web](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf). Technical Report. Stanford InfoLab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank\n",
    "Q: For any search engine (e.g., chrome), if a user searches a term, how does the search engine decide the order of web pages to display?\n",
    "\n",
    "- The frequency of a term appears in the webpage. Doesn't usually work well, because it's vulnerable to \"Google bombing\" (repeating the term a lot in a page in the hopes that it'll go up in the rankings)\n",
    "- **Popularity**: the numbers of links to that page\n",
    "- **Quality**: the quality of the links to that page\n",
    "> Being linked from ten low-follower blog post is not the same as getting one link from the front page of Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./PR.png\"> # width=\"400\" align=left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larry **Page** and Sergey Brin set out to create the **PageRank algorithm**for ranking of websites for their search engine:\n",
    "- [wikipedia definition](https://en.wikipedia.org/wiki/PageRank) \n",
    "- considers the ranking of webpage based on the number and quality of links between pages \n",
    "- computes the probability that a person will end up in a given page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can talk about the algorithm, we need to come up with a **model** that allows us to reason about this problem. What are we concerned with?\n",
    "\n",
    "- Websites\n",
    "- Links between websites\n",
    "\n",
    "We can **model this as a graph**:\n",
    "- Review: vertex, edge, in-degree, out-degree\n",
    "- Our **goal** is to compute the probability that a page will be visited, based on the structure of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"web-graph.png\" width=\"400\" align=left>, <img src=\"graph.png\" width=\"200\" align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is provided in a text file (i.e., tiny.txt) with information about the number of pages and the links between the pages. The graph we saw earlier would be represented by the following file:\n",
    "\n",
    "    5\n",
    "    0 1\n",
    "    1 2\n",
    "    1 2\n",
    "    1 3\n",
    "    1 3\n",
    "    1 4\n",
    "    2 3\n",
    "    3 0\n",
    "    4 0\n",
    "    4 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: How do we represent the graph internally?\n",
    "\n",
    "Use an adjacency matrix: the value at location (i, j) is the number of links from page i to page j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./graph.png\" width=\"200\" align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pagerank import read_graph\n",
    "page_links, out_degree = read_graph(\"tiny.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0, 0],\n",
       " [0, 0, 2, 2, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_links # the value at location (i, j) is the number of links from page i to page j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 1, 1, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_degree # row summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to compute the page popularity (i.e., probability that a page will be visited), based on the structure of the graph. There are multiple ways of doing this. One way is to simulate the behaviour of a **typical user** browsing the web. We will use a crude but useful model of a \"random surfer\":\n",
    "\n",
    "- The user starts at a given page, and then choose the next page as follows:\n",
    "  - 90% of the time, the user will follow a link on the current page (the link is chosen randomly, but with probability proportional to the ratio of outgoing links)\n",
    "  - 10% of the time, the user will just go to a random page (regardless of whether it is linked from the current page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./graph.png\" width=\"100\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the user starts at page 0, the probability of this user moves to page 1:\n",
    "- link probability: 0.9 * (the number of links from 0 to 1/the total number of links goes out from 0) \n",
    "> 0.9 * (1/1) = 0.9 <br>\n",
    "\n",
    "- leap probability: 0.1 * (1/the total number of pages)\n",
    "> 0.1 * (1/5) = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./PR_graph.png\" width=\"400\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./PR_prob.png\" width=\"800\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a **transition matrix** to record the probability of going from page i to page j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition(out_degree):\n",
    "    \"\"\"\n",
    "    Initialize a transition matrix with 0.0 probability\n",
    "    \"\"\"\n",
    "    n = len(out_degree)\n",
    "\n",
    "    # Create a n x n \"matrix\"(using lists of lists)\n",
    "    transition_matrix = []\n",
    "    for i in range(n):\n",
    "        transition_matrix.append([0.0]*n) # initialize all probabilities to 0.0\n",
    "            \n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Working with matrices (represented as lists of lists) is a bit messier than working with lists (in particular, creating an empty matrix requires using a for loop, and accessing matrices is typically done with index variables). Later in the quarter, we'll see a library called **NumPy** that allows us to work with matrices more efficiently and elegantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_transition(out_degree) # Initialize the transition probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the probability from page i to page j:\n",
    "- 90% of the times, the user goes to page \"j\" with a probability proportional to the number of links from \"i\" to \"j\": ``0.9 * (count(i,j)/out_degree of i)``\n",
    "- 10% of the times, the user just randomly pick any page: ``0.1 * (1/n)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition(page_links, out_degree):\n",
    "    \"\"\"\n",
    "    Revise the function:\n",
    "        - Initialize the transition matrix with 0.0 probabilities\n",
    "        - Calculate the real probability from page i to page j\n",
    "    \"\"\"\n",
    "    n = len(out_degree)\n",
    "\n",
    "    # Create an empty n x n \"matrix\" (using lists of lists)\n",
    "    transition_matrix = []\n",
    "    for i in range(n):\n",
    "        transition_matrix.append([0.0]*n)   \n",
    "\n",
    "    # Iterate over every location (i,j) and fill in the probability from page i to page j\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            transition_matrix[i][j] = (0.9 * page_links[i][j]/out_degree[i]) + (0.1 * 1/n)\n",
    "\n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = compute_transition(page_links, out_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.02, 0.92, 0.02, 0.02, 0.02],\n",
       " [0.02, 0.02, 0.38, 0.38, 0.19999999999999998],\n",
       " [0.02, 0.02, 0.02, 0.92, 0.02],\n",
       " [0.92, 0.02, 0.02, 0.02, 0.02],\n",
       " [0.47000000000000003, 0.02, 0.47000000000000003, 0.02, 0.02]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the random surfer (i.e., the user that browses the web)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: How do we figure out what the next page is?\n",
    "\n",
    "Let's say we're in page 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47000000000000003, 0.02, 0.47000000000000003, 0.02, 0.02]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to choose a page according to the given distribution for that page (i.e., page 0 with probability 0.47, page 1 with probability 0.02, etc.)\n",
    "\n",
    "**Q**: Surfer is on page i, how to choose the next page j?\n",
    "- Row i in the transition matrix shows the probability from page i to other pages.\n",
    "- Compute the cumulative probabilities for row i.\n",
    "- Generate a random number between 0.0 and 1.0.\n",
    "- Choose page j based on the interval where r lies (i.e., we pick the first cumulative probability that is greater than r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./random_walker.png\" width=\"800\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user is now at page 4, how to determine the next page? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "probabilities = transition_matrix[4]\n",
    "\n",
    "n = len(transition_matrix) # the total number of web pages\n",
    "r = random.uniform(0.0, 1.0) # randomly generate a prob and choose the next page based on it\n",
    "psum = 0.0 # the cumulative sum\n",
    "\n",
    "for j in range(n): # iterate over all the pages\n",
    "    psum += probabilities[j]\n",
    "    if psum >= r: # stops when the cumulative probability is greater than r\n",
    "        print(j)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734781926543613"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly generate a value in the uniform distribution\n",
    "r = random.uniform(0.1, 1.0)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_move(transition_matrix, current_page):\n",
    "    \"\"\"\n",
    "    The user is at current page, decide the next page to go based on the transition matrix\n",
    "    \"\"\"\n",
    "    n = len(transition_matrix) # the total number of web pages\n",
    "    r = random.uniform(0.0, 1.0)\n",
    "    psum = 0.0\n",
    "\n",
    "    for j in range(n):\n",
    "        psum += transition_matrix[current_page][j]\n",
    "        if psum >= r:\n",
    "            return j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user is currently at page 4 and which is the most likely page to go? We **simulate this process 1000 times** and keep a count of how many times each page is the next page to move to. Then, we can check the distribution of the possible next pages, which gives us a rough approximation of the possibility that an arbitrary user would visit that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulation = 1000\n",
    "\n",
    "nextpage_visits = [0]*len(transition_matrix) # record the frequency of a page being visited\n",
    "\n",
    "current_page = 4\n",
    "for i in range(num_simulation):\n",
    "    next_page = make_one_move(transition_matrix, current_page)\n",
    "    nextpage_visits[next_page] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 478\n",
      "1 15\n",
      "2 462\n",
      "3 29\n",
      "4 16\n"
     ]
    }
   ],
   "source": [
    "for i, count in enumerate(nextpage_visits):\n",
    "    print(i, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./graph.png\" width=\"100\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user starts on page 0, and then **takes 1000 steps of move**, what is the frequency that each page is being visited during this process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "\n",
    "transition_matrix = compute_transition(page_links, out_degree)\n",
    "n = len(transition_matrix)\n",
    "times_visited = [0]*n # record the frequency of a page being visited\n",
    "\n",
    "page = 0 # start from page 0\n",
    "for t in range(num_steps):\n",
    "    page = make_one_move(transition_matrix, page) # update the page after every move\n",
    "    times_visited[page] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 269\n",
      "1 260\n",
      "2 151\n",
      "3 244\n",
      "4 76\n"
     ]
    }
   ],
   "source": [
    "# For the 1000 steps of move, the distribution of pages being visted\n",
    "for i, count in enumerate(times_visited):\n",
    "    print(i, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put this in a function and have it print the normalized counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_surfer(transition_matrix, num_steps):\n",
    "    \"\"\"\n",
    "    Simulate the behavior of a random surfer\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(transition_matrix)\n",
    "    page = 0 # start from page 0\n",
    "    times_visited = [0]*n\n",
    "\n",
    "    # pages being visited in num_steps of move\n",
    "    for t in range(num_steps):\n",
    "        page = make_one_move(transition_matrix, page) # the page get updated\n",
    "        times_visited[page] += 1\n",
    "\n",
    "    # normalization: change count to probability \n",
    "    for i, count in enumerate(times_visited):\n",
    "        v = count / num_steps\n",
    "        print(i, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.272\n",
      "1 0.268\n",
      "2 0.146\n",
      "3 0.242\n",
      "4 0.072\n"
     ]
    }
   ],
   "source": [
    "# the rank of the page popularity during 1000 steps of move: \n",
    "random_surfer(transition_matrix, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularities match with the graph\n",
    "Page 3 has three inbound links (popular). <br>\n",
    "Page 0 has two inbound links, and one link is from the popular page 3. <br>\n",
    "Page 1 has one inbound link from the popular page 0. <br>\n",
    "\n",
    "Page 2 has three inbound links, but neither page 1 nor page 4 is popular. <br>\n",
    "Page 4 has one non-popular inbound link from page 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./graph.png\" width=\"200\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Thinking:\n",
    "- Goal: rank pages based on the popularity\n",
    "- Decomposition/abstraction\n",
    "> Popularity: the probability that a page will be visited<br>\n",
    "> compute popularity based on the structure of the graph. <br>\n",
    "- Modeling:\n",
    "> Graph representation of the data <br>\n",
    "> links: nodes <br>\n",
    "> connections between links: edges<br>\n",
    "> similate the random surfer: 90%: 10% <br>\n",
    "- Algorithms:\n",
    "\n",
    "The pseudocode:\n",
    "    \n",
    "    page_links, out_degree = Load data\n",
    "    transition_matrix = <compute transition matrix>\n",
    "    times_visited = <list of size N>\n",
    "    for i in range(num_steps):\n",
    "        page = <take a step with the random surfer>\n",
    "        times_visited[page] += 1\n",
    "    \n",
    "    for c in times_visited:\n",
    "        print c / num_steps\n",
    "\n",
    "- Complexity:\n",
    "> matrix representation <br>\n",
    "> iterate over and fill in every cell in the transition matrix <br>\n",
    "> the frequency a node is visited during random walk <br>\n",
    "> the number of moves for random walk <br>\n",
    "- Divide each part into a specific function. \n",
    "> compute_transition <br>\n",
    "> make_one_move <br>\n",
    "> random_surfer <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.27\n",
      "1 0.274\n",
      "2 0.14\n",
      "3 0.248\n",
      "4 0.068\n"
     ]
    }
   ],
   "source": [
    "from pagerank import read_graph\n",
    "\n",
    "counts, out_degree = read_graph(\"tiny.txt\")\n",
    "transition_matrix = compute_transition(page_links, out_degree)\n",
    "random_surfer(transition_matrix, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.002\n",
      "1 0.012\n",
      "2 0.009\n",
      "3 0.002\n",
      "4 0.01\n",
      "5 0.011\n",
      "6 0.067\n",
      "7 0.029\n",
      "8 0.011\n",
      "9 0.031\n",
      "10 0.002\n",
      "11 0.029\n",
      "12 0.009\n",
      "13 0.042\n",
      "14 0.02\n",
      "15 0.022\n",
      "16 0.014\n",
      "17 0.006\n",
      "18 0.033\n",
      "19 0.026\n",
      "20 0.004\n",
      "21 0.035\n",
      "22 0.059\n",
      "23 0.045\n",
      "24 0.007\n",
      "25 0.001\n",
      "26 0.0\n",
      "27 0.011\n",
      "28 0.055\n",
      "29 0.001\n",
      "30 0.039\n",
      "31 0.029\n",
      "32 0.02\n",
      "33 0.011\n",
      "34 0.021\n",
      "35 0.019\n",
      "36 0.005\n",
      "37 0.032\n",
      "38 0.009\n",
      "39 0.026\n",
      "40 0.019\n",
      "41 0.029\n",
      "42 0.024\n",
      "43 0.012\n",
      "44 0.036\n",
      "45 0.001\n",
      "46 0.014\n",
      "47 0.021\n",
      "48 0.017\n",
      "49 0.011\n"
     ]
    }
   ],
   "source": [
    "page_links, out_degree = read_graph(\"medium.txt\")\n",
    "transition_matrix = compute_transition(page_links, out_degree)\n",
    "random_surfer(transition_matrix, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
